<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html><head><title>DeepDoom</title>

<style type="text/css">
body {
font-family: "Courier New",Courier,monospace;
font-weight: normal;
font-style: normal;
text-transform: none;
text-align: left;
background-color: #43e8ff;
}
</style>
</head>
<body>
<h1 style="color: rgb(253, 5, 19);"><span>DeepDoom</span></h1>
<h2>About</h2>
<hr>
<p>Applying Deep Reinforcement Learning Techniques on the VizDoom
environment to learn
navigation behaviors. Our goal is to train Deep Q-Learning Networks on
simple navigational
tasks and combining them to solve more complex navigational tasks.</p>
<p>Our Deep Q-Learning implementation is based on the following
sources:</p>
<ul>
<li>
<p><a href="https://github.com/farizrahman4u/qlearning4k">Qlearning4k</a></p>
</li>
<li>
<p><a href="https://www.cs.toronto.edu/%7Evmnih/docs/dqn.pdf">Playing
Atari with Deep Reinforcement Learning</a></p>
</li>
<li>
<p><a href="http://www.nature.com/nature/journal/v518/n7540/full/nature14236.html">Human-level
control through deep reinforcement learning</a></p>
</li>
</ul>
<h4>Group Roles:</h4>
<h5>Rafael Zamora</h5>
<ul>
<li>Team Leader</li>
<li>Machine Learning Specialist/A.I. Designer</li>
</ul>
<h5>Lauren An</h5>
<ul>
<li>Support Programmer</li>
</ul>
<h5>Will Steele</h5>
<ul>
<li>Hardware Spectialist</li>
<li>Head of Documentation</li>
</ul>
<h5>Josh Hidayat</h5>
<ul>
<li>Head of Data Gathering</li>
</ul>
<h2>Scenarios</h2>
<hr>
<p>We designed a set of scenarios where the agent will learn
specific behaviors. These
scenarios where created using Doom Builder and VizDoom. The following
are descriptions of
the scenarios:</p>
<h4>Scenario 1: Rigid Turning</h4>
<h5>Description:</h5>
<p>The purpose of this scenario is to train the AI on navigating
through corridors with sharp 90° turns. Map is a rigid S-shape with
wall and floor textures that are randomly determined at the time of
loading
the map. The player gets rewarded for navigating from one end of the
'S' to the other, and gets penalized for bumping into walls.</p>
<p><em>Available Actions</em>: [MOVE_FORWARD,
MOVE_BACKWARD, TURN_LEFT, TURN_RIGHT]</p>
<h5>Goal Function:</h5>
<ul>
<li><b>+50</b> reward checkpoints</li>
<li><b>+100</b> level exit</li>
<li><b>-10</b> hitting walls</li>
<li><b>-1</b> living reward</li>
</ul>
<h5>Files:</h5>
<ul>
<li><a href="https://github.com/Atlas-Soft/DeepDoom/blob/master/src/wads/corridors.wad">
rigid_turning.wad</a></li>
<li><a href="https://github.com/Atlas-Soft/DeepDoom/tree/master/src/configs/rigid_turning.cfg">
rigid_turning.cfg</a></li>
</ul>
<h4>Scenario 2: Exit Finding</h4>
<h5>Description:</h5>
<p></p>
<h5>Goal Function:</h5>
<ul>
<li></li>
</ul>
<h5>Files:</h5>
<ul>
<li></li>
</ul>
<h2>Results:</h2>
<p>In Progress;<br>
The new Q-Learning implementation is currently training. This process
will take awhile, giving us time to work on documentation.
Stay tuned for more!</p>
<a href="https://github.com/marqt/vizdoom">VizDoom</a>
<p></p>
<p>-<a href="https://github.com/fchollet/keras">Keras</a></p>
<p>-<a href="http://matplotlib.org/">Matplotlib</a></p>
<h4>Setup and Installation:</h4>
<p>Download or clone repository and install required packages.</p>
<p>The <a href="https://github.com/Atlas-Soft/DeepDoom/blob/master/src">/src/</a>
folder includes all scripts used for this project.</p>
<p>The <a href="https://github.com/Atlas-Soft/DeepDoom/blob/master/src/wads">/src/wads/</a>
folder contains the wad files for the scenarios.</p>
<p>The <a href="https://github.com/Atlas-Soft/DeepDoom/blob/master/src/configs">/src/configs/</a>
folder contains the config files for the scenarios.</p>
<p></p>
<p><small>Last Edited 2/17/2017</small></p>
</body></html>